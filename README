
This is code which was used for extacting and analyzing the Bilingual Aphasia Test Android app (Cook, Marquis, Achim 2011 presented at The Academy of Aphasia 2011 - Montreal)). To know more about the archetecture and what Open Source projects were incorporated into this you can look at the Experimenter WebApp in this pdf: http://ilanguagelab.googlecode.com/files/cook%2Cmarquis%2Cachim-2011-Aphasia_assesment_on_Android_recording_voice_eye_gaze_and_touch_for_the_BAT_compressed.pdf

You can think of this as the Experimentor's tool. The tablet can connect to your laptop, send the files to your laptop. The tool has two functions

1. Extract the raw data
2. Analyze/visualize the data


There is a "WATCHME" you TubeVideo to show what this project does. http://www.youtube.com/watch?v=8SNhUbzkk4k The code is also running with our data on the web. You can play with it here http://openlanguage.ca:8136/touch_response_visualizer.html



The audience of this project:

* open source programmers
* researchers who program, or have a programmer in their team who can adapt the code to their needs


There is a "moderatly user friendly" Installer for Mac OS Snow Leopard or Lion which can be used to visualize the sample data and see what this code does. User be-warned: its a very young project, so like a baby it often bables, burps and sometimes spits up unexpectedly. Its heavy 200MB but it sets up your laptop to do some significant data crunching. Email me and I can send you a link. 

The next steps:

To encourage us  you can "watch" our project, "fork" the code, and even send us "pull requests" if you want to contribute your modifications.

